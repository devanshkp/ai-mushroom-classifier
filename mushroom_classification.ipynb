{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab369497",
   "metadata": {},
   "source": [
    "# 1. Setup and Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5332b04c-c28f-4078-93b9-1f9e740a125e",
   "metadata": {},
   "source": [
    "## 1.1 Import Dependencies and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5f509396",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9f010ec8-c110-4434-9a74-401c9f7f584b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET_PATH = \"C:/Users/bluew/Downloads/dataset\"\n",
    "species = os.listdir(DATASET_PATH)\n",
    "len(species)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9aa37f7-6b6f-4cfe-9a10-106398d8457e",
   "metadata": {},
   "source": [
    "# 2. Preprocess Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d94cbfa-dfd8-439f-9104-c54807374f8c",
   "metadata": {},
   "source": [
    "## 2.1 Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4d0f0b21-3256-49a8-95cb-3c26d51c5dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe92081b-beb9-4ec8-b95d-ff5c1477da4e",
   "metadata": {},
   "source": [
    "## 2.2 Load Dataset and split into training & validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1dd32225-1ad3-445f-b1ec-8cf2ef4acb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 77382 files belonging to 100 classes.\n",
      "Using 54168 files for training.\n",
      "Found 77382 files belonging to 100 classes.\n",
      "Using 23214 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# Training dataset\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATASET_PATH,\n",
    "    validation_split=0.3,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Validation+Test dataset\n",
    "val_test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATASET_PATH,\n",
    "    validation_split=0.3,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "val_size = int(tf.data.experimental.cardinality(val_test_dataset).numpy() * 0.5)\n",
    "\n",
    "# Split val_test_dataset into validation and test datasets\n",
    "val_dataset = val_test_dataset.take(val_size)\n",
    "test_dataset = val_test_dataset.skip(val_size)\n",
    "\n",
    "# Class names\n",
    "dataset_cat = train_dataset.class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2b53db-b062-499a-9339-710f87032e3e",
   "metadata": {},
   "source": [
    "## 2.3 Normalize the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d80ce197-9814-4faf-96c0-9e7afdb9d96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "\n",
    "train_dataset = train_dataset.map(lambda x, y: (normalization_layer(x), y))\n",
    "val_dataset = val_dataset.map(lambda x, y: (normalization_layer(x), y))\n",
    "test_dataset = test_dataset.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44d307f-d398-4ee3-bfba-03b91c293bb3",
   "metadata": {},
   "source": [
    "## 2.4 Prefetch Images to Improve Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5aea8509-20d0-4153-afd6-2c5397b80f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_dataset = train_dataset.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_dataset = val_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset = test_dataset.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621ff74a-af87-429e-8294-570cccade66c",
   "metadata": {},
   "source": [
    "## 2.5 Plot some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf1ecd1-21bf-4a3a-8672-ed369e96d697",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for image, labels in train_dataset.take(1):\n",
    "    for i in range(9):\n",
    "        plt.subplot(3, 3, i + 1)\n",
    "        # Convert image[i] from float32 to uint8 (0-255 range)\n",
    "        img = image[i].numpy() * 255.0  # scale back to 0-255\n",
    "        img = img.astype(np.uint8)      # convert to uint8\n",
    "        plt.imshow(img)\n",
    "        plt.title(dataset_cat[labels[i]])\n",
    "        plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2770c6-cb3f-4829-b631-d9204e39344f",
   "metadata": {},
   "source": [
    "# 3. Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fac644-9b52-435e-b26d-197ce78b81fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15753186-441f-4bbb-8716-d2f075b5295e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TensorFlow)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
